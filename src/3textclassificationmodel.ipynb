{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('../data/dataset_tweet_sentimen_tayangan_tv.csv')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Acara TV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby(['Acara TV', 'Sentiment'])['Id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "clean_text = []\n",
    "\n",
    "for text in dataset['Text Tweet']:\n",
    "    clean_text.append(p.clean(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "\n",
    "Mengubah semua huruf menjadi huruf kecil semua untuk mengurangi variansi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_text=[]\n",
    "\n",
    "for text in clean_text:\n",
    "    lower_text.append(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_punct(text):\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punct_text=[]\n",
    "\n",
    "for text in lower_text:\n",
    "    no_punct_text.append(remove_punct(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, ArrayDictionary, StopWordRemover\n",
    "\n",
    "# membuat object untuk menghilankan stopwords\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "\n",
    "# membuat objek stopwords\n",
    "stopword = stop_factory.create_stop_word_remover()\n",
    "\n",
    "# membuat list kosong untuk menyimpan hasil\n",
    "no_stopwords_text = []\n",
    "\n",
    "# membuit loop untuk menghilangkan stopwords\n",
    "for text in no_punct_text:\n",
    "    no_stopwords_text.append(stopword.remove(text))\n",
    "\n",
    "# melihat hasil\n",
    "no_stopwords_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library untuk mengembalikan ke dalam bentuk kata dasar\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# membuat fungsi untuk stemming\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# membuat list kosong untuk menyimpan hasil\n",
    "stemmed_text = []\n",
    "\n",
    "# melakukan looping untuk melakukan stemming pada setiap elemen\n",
    "for text in no_stopwords_text:\n",
    "    stemmed_text.append(stemmer.stem(text))\n",
    "\n",
    "# melihat hasil stemming\n",
    "stemmed_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['cleaned_text'] = stemmed_text\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=[]\n",
    "\n",
    "for text in stemmed_text:\n",
    "    token.extend(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "all_words = list(itertools.chain(token))\n",
    "\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "count_words = collections.Counter(all_words)\n",
    "\n",
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_freq = pd.DataFrame(count_words.most_common(30),\n",
    "                            columns = ['words', 'count'])\n",
    "\n",
    "df_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_doc = dataset[dataset['Sentiment'] == 'negative']['cleaned_text']\n",
    "\n",
    "token_neg = []\n",
    "\n",
    "for text in negative_doc:\n",
    "    token_neg.extend(text.split())\n",
    "\n",
    "all_words_neg = list(itertools.chain(token_neg))\n",
    "\n",
    "all_words_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = collections.Counter(all_words_neg)\n",
    "\n",
    "df_word_freq = pd.DataFrame(count_words.most_common(30), \n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "df_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_doc = dataset[dataset['Sentiment']=='positive']['cleaned_text']\n",
    "\n",
    "token_pos = []\n",
    "\n",
    "for text in pos_doc:\n",
    "    token_pos.extend(text.split())\n",
    "\n",
    "all_words_pos = list(itertools.chain(token_pos))\n",
    "\n",
    "count_words = collections.Counter(all_words_pos)\n",
    "\n",
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_freq = pd.DataFrame(count_words.most_common(30), \n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "df_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['label'] = list(map(lambda x: 1 if x == 'positive' else 0, dataset['Sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['cleaned_text'], \n",
    "                                                    dataset['label'],\n",
    "                                                    random_state = 14,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_counts = tfidf.fit_transform(X_train)\n",
    "X_test_counts = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "BNBclf = BernoulliNB()\n",
    "BNBclf.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred = BNBclf.predict(X_test_counts)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {'model': [], \n",
    "          'confusion_matrix' : [], \n",
    "          'auc' : [], \n",
    "          'accuracy' : []}\n",
    "\n",
    "metric['model'].append('NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "conf_ = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "metric['confusion_matrix'].append(conf_)\n",
    "conf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "metric['auc'].append(_auc)\n",
    "\n",
    "_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ = accuracy_score(y_test, y_pred)\n",
    "\n",
    "metric['accuracy'].append(acc_)\n",
    "\n",
    "acc_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "metric['model'].append(\"LogisticRegression\")\n",
    "\n",
    "\n",
    "conf_ = confusion_matrix(y_test, y_pred)\n",
    "metric[\"confusion_matrix\"].append(conf_)\n",
    "\n",
    "_auc = roc_auc_score(y_test, y_pred)\n",
    "metric[\"auc\"].append(_auc)\n",
    "\n",
    "acc_ = accuracy_score(y_test, y_pred)\n",
    "metric[\"accuracy\"].append(acc_)\n",
    "\n",
    "print('Confusion Matrix: \\n {}'.format(conf_))\n",
    "print('Area Under Curve (AUC): {:,.4f}'.format(_auc))\n",
    "print('Accuracy : {}'.format(acc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svclf = svm.SVC()\n",
    "svclf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclf.predict(X_test_counts)\n",
    "\n",
    "metric['model'].append(\"SVM\")\n",
    "\n",
    "\n",
    "conf_ = confusion_matrix(y_test, y_pred)\n",
    "metric[\"confusion_matrix\"].append(conf_)\n",
    "\n",
    "_auc = roc_auc_score(y_test, y_pred)\n",
    "metric[\"auc\"].append(_auc)\n",
    "\n",
    "acc_ = accuracy_score(y_test, y_pred)\n",
    "metric[\"accuracy\"].append(acc_)\n",
    "\n",
    "print('Confusion Matrix: \\n {}'.format(conf_))\n",
    "print('Area Under Curve (AUC): {:,.4f}'.format(_auc))\n",
    "print('Accuracy : {}'.format(acc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfclf = RandomForestClassifier()\n",
    "rfclf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfclf.predict(X_test_counts)\n",
    "\n",
    "metric['model'].append(\"RandomForest\")\n",
    "\n",
    "\n",
    "conf_ = confusion_matrix(y_test, y_pred)\n",
    "metric[\"confusion_matrix\"].append(conf_)\n",
    "\n",
    "_auc = roc_auc_score(y_test, y_pred)\n",
    "metric[\"auc\"].append(_auc)\n",
    "\n",
    "acc_ = accuracy_score(y_test, y_pred)\n",
    "metric[\"accuracy\"].append(acc_)\n",
    "\n",
    "print('Confusion Matrix: \\n {}'.format(conf_))\n",
    "print('Area Under Curve (AUC): {:,.4f}'.format(_auc))\n",
    "print('Accuracy : {}'.format(acc_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('modelling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3152bca2417f63d8c485a5409aeed29ee044bafe7ca7cac97f729f4661248f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
